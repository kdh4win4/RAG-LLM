# ğŸš€ Enterprise RAG-LLMOps Pipeline

An end-to-end **LLMOps (Large Language Model Operations)** framework designed for building, evaluating, and maintaining production-ready **RAG (Retrieval-Augmented Generation)** systems. This project focuses on reliability, security, and automated quality governance.

## ğŸŒŸ Overview

In modern AI applications, especially for government (SAM.gov) and enterprise sectors, "hallucination" and "outdated information" are critical risks. This project demonstrates a robust pipeline that ensures:
1. **Continuous Integration (CI)** for RAG components.
2. **Continuous Evaluation (CE)** of answer quality using the Ragas framework.
3. **Automated Ingestion** to keep the knowledge base updated.

## ğŸ›  Tech Stack

* **Orchestration**: LangChain
* **LLM**: OpenAI GPT-4o / Claude 3.5
* **Vector Database**: ChromaDB (Open-source, self-hostable)
* **Evaluation**: Ragas (Retrieval-Augmented Generation Assessment)
* **Ops/CI-CD**: GitHub Actions
* **Data Management**: DVC (Data Version Control)

## ğŸ“ Project Structure

```text
â”œâ”€â”€ .github/workflows/       # CI/CD & Automated Evaluation Pipelines
â”‚   â””â”€â”€ eval_rag.yml         # Runs RAGAS metrics on every push
â”œâ”€â”€ data/                    # Source documents (PDF, Markdown, etc.)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py            # Document parsing and Vector DB embedding
â”‚   â”œâ”€â”€ retrieve.py          # Semantic search logic
â”‚   â””â”€â”€ chain.py             # LLM RAG chain implementation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_eval.py         # Automated QA tests (Faithfulness, Relevance)
â””â”€â”€ requirements.txt         # Dependency management
